{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMTwithGRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP3H3PaNnx9R"
      },
      "source": [
        "#Model Info:\n",
        "A Gru based Encoder and Decoder with Attention mechanism.\n",
        "Model's Architecture\n",
        "          \n",
        "\n",
        "\n",
        "* Model's Architecture\n",
        "          Encoder:  Uni-directional GRU, 1 layer of GRU cells used\n",
        "          Decoder: Uni-directional GRU with Attention mechanism\n",
        "          Optimizer: Stochastic gradient descent (SGD)\n",
        "          Loss Criterion:  Negative log-likelihood(NLL) Loss\n",
        "          Dropout technique is also used with probability= 0.1\n",
        "          Learning rate=0.01\n",
        " \n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6yJXmcQ6ywW",
        "outputId": "d33b81b5-fa5b-49dc-dfd3-fb4086a285ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEnc3cE3MDAK"
      },
      "source": [
        "#Making all necessary allowed imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjv3BdQeNBa"
      },
      "source": [
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgA_FSGIMV2V"
      },
      "source": [
        "#Creating vocab using  dictionary together with some preprocessing all visualisation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvV1IQSne-li"
      },
      "source": [
        "\n",
        "i=0\n",
        "data={}\n",
        "with open('/content/drive/MyDrive/train/train.csv', 'r') as file:\n",
        "    reader = csv.reader(file, delimiter=',')\n",
        "    for row in reader:\n",
        "        if i==0:\n",
        "            i+=1\n",
        "            continue\n",
        "        else:\n",
        "            data[row[0]]={}\n",
        "            data[row[0]]['src']=row[1]\n",
        "            data[row[0]]['trg']=row[2]\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "j=0\n",
        "test_data={}\n",
        "with open('hindistatements.csv', 'r') as file:\n",
        "    reader = csv.reader(file, delimiter=',')\n",
        "    for row in reader:\n",
        "        if j==0:\n",
        "            j+=1\n",
        "            continue\n",
        "        else:\n",
        "            test_data[row[1]]={}\n",
        "            test_data[row[1]]['src']=row[2]\n",
        "            test_data[row[1]]['trg']=data[row[1]]['trg']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CBWWHnRyPKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78b1885-c926-48a4-b8c2-9f4e470876db"
      },
      "source": [
        "print(test_data['0']['src'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- अंतरिक्ष वाले लोग?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf4BMwoAnvhs",
        "outputId": "91439180-a61c-4514-9952-dd482cf2c3c1"
      },
      "source": [
        "all_len=[]\n",
        "for x in range(len(data)):\n",
        "    all_len.append(len(data[str(x)]['src']))\n",
        "\n",
        "\n",
        "plt.hist(all_len, bins=[0,100,200,300,400,500,600])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC5To3YJNfr5"
      },
      "source": [
        "# some work to find outliers based on length of sentences and remove them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi_FB0VbNZGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e66a75-2801-4c72-8350-11b2fb24ef2b"
      },
      "source": [
        "print(min(all_len))\n",
        "print(all_len.index(min(all_len)))\n",
        "print(data['5933']['trg'])\n",
        "n = len(all_len)\n",
        "Range = max(all_len)- min(all_len)\n",
        "intervals = math.sqrt(n)\n",
        "Width= Range // intervals \n",
        "print(Range)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "5933\n",
            "Huh?\n",
            "2087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua9wrbbitjZe"
      },
      "source": [
        "hindi_len=[0,0,0,0,0,0,0]\n",
        "for x in range(len(data)):\n",
        "    if len(data[str(x)]['src'])<=100:\n",
        "        hindi_len[0]+=1\n",
        "    \n",
        "    if 100<len(data[str(x)]['src'])<=200:\n",
        "        hindi_len[1]+=1\n",
        "        \n",
        "    \n",
        "    if 200<len(data[str(x)]['src'])<=300:\n",
        "        hindi_len[2]+=1\n",
        "\n",
        "    if 300<len(data[str(x)]['src'])<=400:\n",
        "        hindi_len[3]+=1\n",
        "\n",
        "    if 400<len(data[str(x)]['src'])<=500:\n",
        "        hindi_len[4]+=1\n",
        "\n",
        "    if 500<len(data[str(x)]['src'])<=600:\n",
        "        hindi_len[5]+=1\n",
        "\n",
        "    if len(data[str(x)]['src'])>600:\n",
        "        hindi_len[6]+=1\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9mK8NiFu5MS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd300ec-d12e-4772-e45e-b9bc07543a92"
      },
      "source": [
        "print('number of sentences of length less than 100,200,...so on')\n",
        "print(hindi_len)\n",
        "\n",
        "for x in list(data):\n",
        "    if len(data[x]['src'])>300:\n",
        "        result = data.pop(x, None)\n",
        "        \n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = [lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of sentences of length less than 100,200,...so on\n",
            "[89622, 10892, 1490, 243, 52, 15, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVUOXba91KBv",
        "outputId": "2e08e770-92d3-4a64-889e-7c44b483bf13"
      },
      "source": [
        "\n",
        "pairs=[]\n",
        "for x in data:\n",
        "    pairs.append([data[x]['src'],data[x]['trg']])\n",
        "\n",
        "input_lang = Lang('hindi')\n",
        "output_lang = Lang('english')\n",
        "print(\"Total numbwer of Training examples after preprocessing:\" , len(pairs))\n",
        "for pair in pairs:\n",
        "    input_lang.addSentence(pair[0])\n",
        "    output_lang.addSentence(pair[1])\n",
        "for x in test_data:\n",
        "    input_lang.addSentence(test_data[x]['src'])\n",
        "print(\"=========== Words in vocab ==============\")\n",
        "print(input_lang.name, input_lang.n_words)\n",
        "print(output_lang.name, output_lang.n_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total numbwer of Training examples after preprocessing: 102004\n",
            "=========== Words in vocab ==============\n",
            "hindi 72018\n",
            "english 73520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLQjYQB2Rneh"
      },
      "source": [
        "# The template for the Encoder and Attention decoder Architecture \n",
        "This section uses framework provided in the pytorch tutorial heavily\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETjY1lKMfL78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c848974-a347-433b-98da-11a17b552992"
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "class EncoderGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderGRU, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttentionGRU(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=100):\n",
        "        super(AttentionGRU, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOkv3cTTm8W"
      },
      "source": [
        "#Traiing the model and measuring its performance  on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH1H3a_xkcb1"
      },
      "source": [
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=100):\n",
        "    \n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < 0.4 else False\n",
        "\n",
        "    if use_teacher_forcing == True:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  \n",
        "\n",
        "    else:\n",
        "    \n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() \n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "def Measure(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
        "\n",
        "    if device=='cuda':\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() \n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "    \n",
        "    print_loss_total = 0  \n",
        "    plot_loss_total = 0  \n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('Training examples processed:',iter)\n",
        "            print('Total average loss:, ', round(print_loss_avg,3))\n",
        "\n",
        "    indexes = [input_lang.word2index[word] for word in sentence.split(' ')]\n",
        "    indexes.append(EOS_token)\n",
        "    input_tensor=torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "    input_length = input_tensor.size()[0]\n",
        "\n",
        "hidden_size = 256\n",
        "encoder = EncoderGRU(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttentionGRU(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "Epochs=20\n",
        "for e in range(Epochs):\n",
        "    print(\"Epoch :\",e+1)\n",
        "    Measure(encoder, decoder, 100000, print_every=5000)\n",
        "    print(\"=================================================================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTZ92uvRUMKG"
      },
      "source": [
        "# Get predicted translation by the model.\n",
        "Fetching the predicted Translation and saving it in answer.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vX-FtxiiTCB"
      },
      "source": [
        "file1 = open(\"answer.txt\",\"w\")\n",
        "\n",
        "def Translator(encoder, decoder, sentence, max_length=100):\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        indexes = [input_lang.word2index[word] for word in sentence.split(' ')]\n",
        "        indexes.append(EOS_token)\n",
        "        input_tensor=torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device) \n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words\n",
        "\n",
        "\n",
        "for x in test_data:\n",
        "    output_words = Translator(encoder, decoder, test_data[x]['src'])\n",
        "    output_words.pop()\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    file1.write(output_sentence+'\\n')\n",
        "\n",
        "file1.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}